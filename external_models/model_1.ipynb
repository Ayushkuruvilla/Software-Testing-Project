{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b33253a3-267f-4d41-990d-ec262343af8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\chris\\.virtualenvs\\Software-Testing-Project-CokUEsl4\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'ot': ot_distance will be unavailable. To install, run:\n",
      "pip install 'aif360[OptimalTransport]'\n",
      "WARNING:root:No module named 'tqdm': FACTS will be unavailable. To install, run:\n",
      "pip install 'aif360[FACTS]'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import to_onnx\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skl2onnx import convert_sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# define a XGBoost classifier\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from aif360.sklearn.datasets import fetch_compas\n",
    "from aif360.sklearn.metrics import disparate_impact_ratio, consistency_score, generalized_entropy_error\n",
    "from aif360.sklearn.detectors import bias_scan\n",
    "from aif360.sklearn.inprocessing import AdversarialDebiasing\n",
    "from aif360.datasets import BinaryLabelDataset, StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from xgboost import XGBClassifier\n",
    "from skl2onnx import update_registered_converter\n",
    "from skl2onnx.common._apply_operation import apply_identity\n",
    "from skl2onnx.common.shape_calculator import (\n",
    "    calculate_linear_classifier_output_shapes,\n",
    ")\n",
    "from skl2onnx import update_registered_converter\n",
    "from onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore runtime warnings\n",
    "# Temporarily adjust pandas display settings for large DataFrames\n",
    "pd.set_option('display.max_rows', 100)  # Ensure 100 rows can be displayed\n",
    "pd.set_option('display.max_columns', None)  # Ensure all columns can be displayed\n",
    "pd.set_option('display.width', None)  # Automatically adjust display width to terminal size\n",
    "pd.set_option('display.max_colwidth', None)  # Ensure full width of column content is shown\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)  # Format the float numbers for better readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72505f79-7a14-4204-873b-2a471fe2404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/investigation_train_large_checked_adjusted3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4c222aa-227d-4004-bb5d-4ecfad1fa093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the target and features\n",
    "y = data['checked']  # Assuming 'checked' is the target column\n",
    "X = data.drop(['checked', 'Ja', 'Nee'], axis=1)\n",
    "\n",
    "# Ensure features are float32\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "# Step 3: Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "905222f5-6db9-49f1-afd5-f60d88381561",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_session = rt.InferenceSession(\"./received_folder/model_1.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35ef4cb6-e0dd-4712-b705-9baaf1a3572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prediction_consistency(testing_session, X_test, feature_name, values):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of cases where predictions are the same for different values of a given feature.\n",
    "\n",
    "    Parameters:\n",
    "        testing_session (InferenceSession): The ONNX model inference session.\n",
    "        X_test (pd.DataFrame): Test dataset.\n",
    "        feature_name (str): The feature to modify.\n",
    "        values (list): List of two values to compare for the feature.\n",
    "\n",
    "    Returns:\n",
    "        float: Fraction of cases where predictions are the same.\n",
    "    \"\"\"\n",
    "    same_predictions_count = 0\n",
    "    total_samples = len(X_test)\n",
    "\n",
    "    # Get the input name expected by the ONNX model\n",
    "    input_name = testing_session.get_inputs()[0].name\n",
    "\n",
    "    for _, row in X_test.iterrows():\n",
    "        # Convert the row to a DataFrame with one row\n",
    "        X_sample = pd.DataFrame([row])\n",
    "\n",
    "        # Modify the feature for the first value\n",
    "        X_sample_1 = X_sample.copy()\n",
    "        X_sample_1[feature_name] = values[0]\n",
    "        y_pred_1 = testing_session.run(None, {input_name: X_sample_1.values.astype(np.float32)})[0]\n",
    "\n",
    "        # Modify the feature for the second value\n",
    "        X_sample_2 = X_sample.copy()\n",
    "        X_sample_2[feature_name] = values[1]\n",
    "        y_pred_2 = testing_session.run(None, {input_name: X_sample_2.values.astype(np.float32)})[0]\n",
    "\n",
    "        # Check if predictions are the same\n",
    "        if np.array_equal(y_pred_1, y_pred_2):\n",
    "            same_predictions_count += 1\n",
    "\n",
    "    # Calculate the fraction of cases where predictions are the same\n",
    "    return same_predictions_count / total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfa9e172-a5d5-4b9a-a33d-39b0454092c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cases where predictions are the same for age 25 and 40: 1.0\n",
      "Fraction of cases where predictions are the same for men and women: 0.976736899819848\n",
      "Fraction of cases where predictions are the same for dutch speakers and non-dutch speakers: 0.9680034463852119\n",
      "Fraction of cases where predictions are the same for people with or without children: 1.0\n"
     ]
    }
   ],
   "source": [
    "age_fraction = calculate_prediction_consistency(\n",
    "    testing_session=testing_session,\n",
    "    X_test=X_test,\n",
    "    feature_name='persoon_leeftijd_bij_onderzoek',\n",
    "    values=[25, 40]\n",
    ")\n",
    "print(\"Fraction of cases where predictions are the same for age 25 and 40:\", age_fraction)\n",
    "\n",
    "\n",
    "gender_fraction = calculate_prediction_consistency(\n",
    "    testing_session=testing_session,\n",
    "    X_test=X_test,\n",
    "    feature_name='persoon_geslacht_vrouw',\n",
    "    values=[0.0, 1.0]\n",
    ")\n",
    "print(\"Fraction of cases where predictions are the same for men and women:\", gender_fraction)\n",
    "\n",
    "language_fraction = calculate_prediction_consistency(\n",
    "    testing_session=testing_session,\n",
    "    X_test=X_test,\n",
    "    feature_name='persoonlijke_eigenschappen_taaleis_voldaan',\n",
    "    values=[0.0, 1.0]\n",
    ")\n",
    "print(\"Fraction of cases where predictions are the same for dutch speakers and non-dutch speakers:\", language_fraction)\n",
    "\n",
    "children_fraction = calculate_prediction_consistency(\n",
    "    testing_session=testing_session,\n",
    "    X_test=X_test,\n",
    "    feature_name='relatie_kind_heeft_kinderen',\n",
    "    values=[0.0, 1.0]\n",
    ")\n",
    "print(\"Fraction of cases where predictions are the same for people with or without children:\", children_fraction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d1e47a8-713f-46a4-a244-47269e5c99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_for_groups(pipe, x_training, y_training, x_testing, y_testing, group_dicts):\n",
    "    \"\"\"\n",
    "    Tests the model and calculates fairness metrics for multiple privileged/unprivileged group definitions.\n",
    "    \n",
    "    Args:\n",
    "        pipe: The model pipeline to test.\n",
    "        x_training: Training features.\n",
    "        y_training: Training labels.\n",
    "        x_testing: Testing features.\n",
    "        y_testing: Testing labels.\n",
    "        group_dicts: List of dictionaries defining privileged and unprivileged groups.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with calculated metrics for each privileged/unprivileged group combination.\n",
    "    \"\"\"\n",
    "    def intoBinary(data, attribute, split):\n",
    "        \"\"\"\n",
    "        Converts a continuous attribute into binary based on a percentile split.\n",
    "        \"\"\"\n",
    "        sorted_data = data.sort_values(by=attribute)\n",
    "        split_index = int(len(sorted_data) * split)\n",
    "        split_threshold = sorted_data.iloc[split_index][attribute]\n",
    "        print(f\"Boundary for {attribute}: {split_threshold}\")\n",
    "        binary_attribute = pd.Series(0, index=data.index)\n",
    "        binary_attribute[sorted_data[attribute] > split_threshold] = 1\n",
    "        data[attribute] = binary_attribute\n",
    "        return data\n",
    "\n",
    "    if isinstance(pipe, rt.InferenceSession):  # ONNX model\n",
    "        print(\"Using ONNX model for predictions\")\n",
    "        predictions = pipe.run(None, {'X': x_testing.values.astype(np.float32)})\n",
    "        y_pred = predictions[0].round().astype(int)  # Ensure predictions are integer class labels\n",
    "    else:  # Assume scikit-learn pipeline\n",
    "        print(\"Training the model\")\n",
    "        pipe.fit(x_training, y_training)\n",
    "        y_pred = pipe.predict(x_testing)\n",
    "\n",
    "    # Prepare a DataFrame with features and predictions\n",
    "    data_frame = pd.concat([x_testing.reset_index(drop=True), pd.DataFrame(y_pred, columns=['checked'])], axis=1)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for group in group_dicts:\n",
    "        protected_attr = group['protected_attribute']\n",
    "        privileged_groups = group['privileged']\n",
    "        unprivileged_groups = group['unprivileged']\n",
    "        \n",
    "        # Convert the protected attribute to binary\n",
    "        data_frame = intoBinary(data_frame, protected_attr, split=0.1)  # Using 0.1 as an example split value\n",
    "\n",
    "        # BinaryLabelDataset creation\n",
    "        bld = BinaryLabelDataset(\n",
    "            df=data_frame,\n",
    "            favorable_label=0,\n",
    "            unfavorable_label=1,\n",
    "            label_names=['checked'],\n",
    "            unprivileged_protected_attributes=[[group['unprivileged_value']]],\n",
    "            privileged_protected_attributes=[[group['privileged_value']]],\n",
    "            protected_attribute_names=[protected_attr]\n",
    "        )\n",
    "        # Count outcomes for privileged and unprivileged groups\n",
    "        privileged_indices = bld.protected_attributes[:, 0] == group['privileged_value']\n",
    "        unprivileged_indices = bld.protected_attributes[:, 0] == group['unprivileged_value']\n",
    "\n",
    "        privileged_labels = bld.labels[privileged_indices]\n",
    "        unprivileged_labels = bld.labels[unprivileged_indices]\n",
    "\n",
    "        privileged_checked_count = (privileged_labels == bld.favorable_label).sum()\n",
    "        privileged_unchecked_count = (privileged_labels == bld.unfavorable_label).sum()\n",
    "\n",
    "        unprivileged_checked_count = (unprivileged_labels == bld.favorable_label).sum()\n",
    "        unprivileged_unchecked_count = (unprivileged_labels == bld.unfavorable_label).sum()\n",
    "\n",
    "        # Print the counts\n",
    "        print(f\"\\nCounts for Protected Attribute '{protected_attr}':\")\n",
    "        print(f\"Privileged Group ({privileged_groups}):\")\n",
    "        print(f\"  Checked (Favorable Outcomes): {privileged_checked_count}\")\n",
    "        print(f\"  Unchecked (Unfavorable Outcomes): {privileged_unchecked_count}\")\n",
    "        print(f\"Unprivileged Group ({unprivileged_groups}):\")\n",
    "        print(f\"  Checked (Favorable Outcomes): {unprivileged_checked_count}\")\n",
    "        print(f\"  Unchecked (Unfavorable Outcomes): {unprivileged_unchecked_count}\")\n",
    "        # Validate the dataset\n",
    "        bld.validate_dataset()\n",
    "\n",
    "        # Metric calculation\n",
    "        metric = BinaryLabelDatasetMetric(bld, privileged_groups=privileged_groups, unprivileged_groups=unprivileged_groups)\n",
    "\n",
    "\n",
    "        \n",
    "        # Metrics\n",
    "        disparate_impact = metric.disparate_impact()\n",
    "        stat_par_diff = metric.statistical_parity_difference()\n",
    "        mean_difference = metric.mean_difference()\n",
    "        consistency = metric.consistency(n_neighbors=3)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"\\nMetrics for protected attribute '{protected_attr}':\")\n",
    "        print(f\"Privileged Groups: {privileged_groups}\")\n",
    "        print(f\"Unprivileged Groups: {unprivileged_groups}\")\n",
    "        print(f\"Disparate Impact: {disparate_impact}\")\n",
    "        print(f\"Statistical Parity Difference: {stat_par_diff}\")\n",
    "        print(f\"Mean Difference: {mean_difference}\")\n",
    "        print(f\"Consistency: {consistency}\")\n",
    "\n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'Protected Attribute': protected_attr,\n",
    "            'Privileged Groups': privileged_groups,\n",
    "            'Unprivileged Groups': unprivileged_groups,\n",
    "            'Disparate Impact': disparate_impact,\n",
    "            'Statistical Parity Difference': stat_par_diff,\n",
    "            'Mean Difference': mean_difference,\n",
    "            'Consistency': consistency\n",
    "        })\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nFairness Metrics Summary:\")\n",
    "    print(results_df)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b887a92e-3769-4d6c-a4f0-1d219510e630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ONNX model for predictions\n",
      "Boundary for persoon_leeftijd_bij_onderzoek: 36.0\n",
      "\n",
      "Counts for Protected Attribute 'persoon_leeftijd_bij_onderzoek':\n",
      "Privileged Group ([{'persoon_leeftijd_bij_onderzoek': 1}]):\n",
      "  Checked (Favorable Outcomes): 18256\n",
      "  Unchecked (Unfavorable Outcomes): 4366\n",
      "Unprivileged Group ([{'persoon_leeftijd_bij_onderzoek': 0}]):\n",
      "  Checked (Favorable Outcomes): 1941\n",
      "  Unchecked (Unfavorable Outcomes): 971\n",
      "\n",
      "Metrics for protected attribute 'persoon_leeftijd_bij_onderzoek':\n",
      "Privileged Groups: [{'persoon_leeftijd_bij_onderzoek': 1}]\n",
      "Unprivileged Groups: [{'persoon_leeftijd_bij_onderzoek': 0}]\n",
      "Disparate Impact: 0.8259609891915709\n",
      "Statistical Parity Difference: -0.14044983561659807\n",
      "Mean Difference: -0.14044983561659807\n",
      "Consistency: [0.788452]\n",
      "Boundary for persoon_geslacht_vrouw: 0.0\n",
      "\n",
      "Counts for Protected Attribute 'persoon_geslacht_vrouw':\n",
      "Privileged Group ([{'persoon_geslacht_vrouw': 0}]):\n",
      "  Checked (Favorable Outcomes): 10352\n",
      "  Unchecked (Unfavorable Outcomes): 2802\n",
      "Unprivileged Group ([{'persoon_geslacht_vrouw': 1}]):\n",
      "  Checked (Favorable Outcomes): 9845\n",
      "  Unchecked (Unfavorable Outcomes): 2535\n",
      "\n",
      "Metrics for protected attribute 'persoon_geslacht_vrouw':\n",
      "Privileged Groups: [{'persoon_geslacht_vrouw': 0}]\n",
      "Unprivileged Groups: [{'persoon_geslacht_vrouw': 1}]\n",
      "Disparate Impact: 1.0104821588642\n",
      "Statistical Parity Difference: 0.008249301243895224\n",
      "Mean Difference: 0.008249301243895224\n",
      "Consistency: [0.788452]\n",
      "Boundary for relatie_overig_kostendeler: 0.0\n",
      "\n",
      "Counts for Protected Attribute 'relatie_overig_kostendeler':\n",
      "Privileged Group ([{'relatie_overig_kostendeler': 0}]):\n",
      "  Checked (Favorable Outcomes): 16288\n",
      "  Unchecked (Unfavorable Outcomes): 3033\n",
      "Unprivileged Group ([{'relatie_overig_kostendeler': 1}]):\n",
      "  Checked (Favorable Outcomes): 3909\n",
      "  Unchecked (Unfavorable Outcomes): 2304\n",
      "\n",
      "Metrics for protected attribute 'relatie_overig_kostendeler':\n",
      "Privileged Groups: [{'relatie_overig_kostendeler': 0}]\n",
      "Unprivileged Groups: [{'relatie_overig_kostendeler': 1}]\n",
      "Disparate Impact: 0.7463218501070542\n",
      "Statistical Parity Difference: -0.21385589283454798\n",
      "Mean Difference: -0.21385589283454798\n",
      "Consistency: [0.788452]\n",
      "\n",
      "Fairness Metrics Summary:\n",
      "              Protected Attribute                        Privileged Groups  \\\n",
      "0  persoon_leeftijd_bij_onderzoek  [{'persoon_leeftijd_bij_onderzoek': 1}]   \n",
      "1          persoon_geslacht_vrouw          [{'persoon_geslacht_vrouw': 0}]   \n",
      "2      relatie_overig_kostendeler      [{'relatie_overig_kostendeler': 0}]   \n",
      "\n",
      "                       Unprivileged Groups  Disparate Impact  \\\n",
      "0  [{'persoon_leeftijd_bij_onderzoek': 0}]            0.8260   \n",
      "1          [{'persoon_geslacht_vrouw': 1}]            1.0105   \n",
      "2      [{'relatie_overig_kostendeler': 1}]            0.7463   \n",
      "\n",
      "   Statistical Parity Difference  Mean Difference           Consistency  \n",
      "0                        -0.1404          -0.1404  [0.7884519986423365]  \n",
      "1                         0.0082           0.0082  [0.7884519986423365]  \n",
      "2                        -0.2139          -0.2139  [0.7884519986423365]  \n"
     ]
    }
   ],
   "source": [
    "group_dicts = [\n",
    "    {\n",
    "        'protected_attribute': 'persoon_leeftijd_bij_onderzoek',\n",
    "        'privileged': [{'persoon_leeftijd_bij_onderzoek': 1}],\n",
    "        'unprivileged': [{'persoon_leeftijd_bij_onderzoek': 0}],\n",
    "        'privileged_value': 1,\n",
    "        'unprivileged_value': 0\n",
    "    },\n",
    "    {\n",
    "        'protected_attribute': 'persoon_geslacht_vrouw',\n",
    "        'privileged': [{'persoon_geslacht_vrouw': 0}],\n",
    "        'unprivileged': [{'persoon_geslacht_vrouw': 1}],\n",
    "        'privileged_value': 0,\n",
    "        'unprivileged_value': 1\n",
    "    },\n",
    "    {\n",
    "        'protected_attribute': 'relatie_overig_kostendeler',\n",
    "        'privileged': [{'relatie_overig_kostendeler': 0}],\n",
    "        'unprivileged': [{'relatie_overig_kostendeler': 1}],\n",
    "        'privileged_value': 0,\n",
    "        'unprivileged_value': 1\n",
    "    }\n",
    "]\n",
    "results_df = test_model_for_groups(\n",
    "    pipe=testing_session, \n",
    "    x_training=X_train, \n",
    "    y_training=y_train, \n",
    "    x_testing=X_test, \n",
    "    y_testing=y_test, \n",
    "    group_dicts=group_dicts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad7fbeb9-b3e7-446f-9c94-69b10ae56630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_by_group(testing_session, X_test, y_test, group_column, group_mapping=None, bins=None, labels=None):\n",
    "    \"\"\"\n",
    "    Evaluate model performance across demographic groups.\n",
    "\n",
    "    Parameters:\n",
    "        testing_session (InferenceSession): The ONNX model inference session.\n",
    "        X_test (pd.DataFrame): Test dataset features.\n",
    "        y_test (pd.Series): True labels for the test dataset.\n",
    "        group_column (str): Column used to define groups.\n",
    "        group_mapping (dict): Mapping of values in `group_column` to group labels.\n",
    "        bins (list): Bin edges for numeric grouping.\n",
    "        labels (list): Labels for bins if numeric grouping is used.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing performance metrics for each group.\n",
    "    \"\"\"\n",
    "    # Copy test data to avoid modification\n",
    "    X_test_grouped = X_test.copy()\n",
    "\n",
    "    # Handle group definitions (mapping or binning)\n",
    "    if group_mapping:\n",
    "        X_test_grouped['group'] = X_test_grouped[group_column].map(group_mapping)\n",
    "    elif bins and labels:\n",
    "        X_test_grouped['group'] = pd.cut(X_test_grouped[group_column], bins=bins, labels=labels)\n",
    "    else:\n",
    "        raise ValueError(\"Provide either `group_mapping` or `bins` and `labels` to define groups.\")\n",
    "\n",
    "    # Drop rows with NaN in the 'group' column\n",
    "    X_test_grouped = X_test_grouped.dropna(subset=['group'])\n",
    "\n",
    "    # Align y_test with X_test_grouped\n",
    "    y_test_aligned = y_test.loc[X_test_grouped.index]\n",
    "\n",
    "    # Debug: Check group distribution\n",
    "    print(\"Group distribution:\\n\", X_test_grouped['group'].value_counts())\n",
    "\n",
    "    # Initialize dictionary to store results\n",
    "    results = {}\n",
    "\n",
    "    # Evaluate performance for each group\n",
    "    for group in X_test_grouped['group'].unique():\n",
    "        # Filter data for the current group\n",
    "        X_group = X_test_grouped[X_test_grouped['group'] == group].drop(columns=['group'])\n",
    "        y_group = y_test_aligned[X_test_grouped['group'] == group]\n",
    "\n",
    "        # Predict using the model\n",
    "        y_pred_group = testing_session.run(None, {'X': X_group.values.astype(np.float32)})[0]\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        accuracy_group = accuracy_score(y_group, y_pred_group)\n",
    "        precision_group = precision_score(y_group, y_pred_group, zero_division=0)\n",
    "        recall_group = recall_score(y_group, y_pred_group, zero_division=0)\n",
    "        f1_score_group = f1_score(y_group, y_pred_group, zero_division=0)\n",
    "\n",
    "        # Store metrics for the group\n",
    "        results[group] = {\n",
    "            'Accuracy': accuracy_group,\n",
    "            'Precision': precision_group,\n",
    "            'Recall': recall_group,\n",
    "            'F1 Score': f1_score_group\n",
    "        }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a343d6e-1c38-47bd-a819-337d550188ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group distribution:\n",
      " group\n",
      "older_adult          8695\n",
      "middle_aged_adult    8234\n",
      "youngish_adult       4013\n",
      "senior               3582\n",
      "young_adult          1010\n",
      "Name: count, dtype: int64\n",
      "Age Group Results:\n",
      "senior: {'Accuracy': 0.907035175879397, 'Precision': 0.5656877897990726, 'Recall': 0.8755980861244019, 'F1 Score': 0.6873239436619718}\n",
      "older_adult: {'Accuracy': 0.908223116733755, 'Precision': 0.37479935794542535, 'Recall': 0.9609053497942387, 'F1 Score': 0.5392609699769053}\n",
      "young_adult: {'Accuracy': 0.902970297029703, 'Precision': 0.8073089700996677, 'Recall': 0.8586572438162544, 'F1 Score': 0.8321917808219178}\n",
      "youngish_adult: {'Accuracy': 0.8888612010964366, 'Precision': 0.7456472369417109, 'Recall': 0.8995433789954338, 'F1 Score': 0.8153973509933775}\n",
      "middle_aged_adult: {'Accuracy': 0.898955550157882, 'Precision': 0.5878155872667399, 'Recall': 0.9296875, 'F1 Score': 0.7202420981842637}\n",
      "Group distribution:\n",
      " group\n",
      "man      13154\n",
      "woman    12380\n",
      "Name: count, dtype: int64\n",
      "Gender Results:\n",
      "woman: {'Accuracy': 0.9068659127625202, 'Precision': 0.6015779092702169, 'Recall': 0.9142685851318945, 'F1 Score': 0.7256721389483702}\n",
      "man: {'Accuracy': 0.8970655313972936, 'Precision': 0.573518915060671, 'Recall': 0.9099660249150623, 'F1 Score': 0.7035901926444834}\n",
      "Group distribution:\n",
      " group\n",
      "other_language    14207\n",
      "not               10097\n",
      "Name: count, dtype: int64\n",
      "Language Results:\n",
      "other_language: {'Accuracy': 0.9234180333638348, 'Precision': 0.5700846660395108, 'Recall': 0.8744588744588745, 'F1 Score': 0.6902050113895216}\n",
      "not: {'Accuracy': 0.8793701099336436, 'Precision': 0.6027201145311382, 'Recall': 0.9397321428571429, 'F1 Score': 0.7344090710859137}\n",
      "Group distribution:\n",
      " group\n",
      "not          16558\n",
      "has_child     8976\n",
      "Name: count, dtype: int64\n",
      "Children Results:\n",
      "not: {'Accuracy': 0.9063292668196642, 'Precision': 0.5584881068752037, 'Recall': 0.8973821989528796, 'F1 Score': 0.6884916649929704}\n",
      "has_child: {'Accuracy': 0.89349376114082, 'Precision': 0.6252204585537919, 'Recall': 0.9304461942257218, 'F1 Score': 0.7478902953586498}\n"
     ]
    }
   ],
   "source": [
    "age_bins = [0, 30, 40, 50, 60, 120]\n",
    "age_labels = ['young_adult', 'youngish_adult', 'middle_aged_adult', 'older_adult', 'senior']\n",
    "\n",
    "age_results = evaluate_model_by_group(\n",
    "    testing_session=testing_session,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    group_column='persoon_leeftijd_bij_onderzoek',\n",
    "    bins=age_bins,\n",
    "    labels=age_labels\n",
    ")\n",
    "\n",
    "print(\"Age Group Results:\")\n",
    "for group, metrics in age_results.items():\n",
    "    print(f\"{group}: {metrics}\")\n",
    "\n",
    "\n",
    "gender_mapping = {1.0: 'woman', 0.0: 'man'}\n",
    "\n",
    "gender_results = evaluate_model_by_group(\n",
    "    testing_session=testing_session,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    group_column='persoon_geslacht_vrouw',\n",
    "    group_mapping=gender_mapping\n",
    ")\n",
    "\n",
    "print(\"Gender Results:\")\n",
    "for group, metrics in gender_results.items():\n",
    "    print(f\"{group}: {metrics}\")\n",
    "\n",
    "language_mapping = {1.0: 'other_language', 0.0: 'not'}\n",
    "\n",
    "language_results = evaluate_model_by_group(\n",
    "    testing_session=testing_session,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    group_column='persoonlijke_eigenschappen_taaleis_voldaan',\n",
    "    group_mapping=language_mapping\n",
    ")\n",
    "\n",
    "print(\"Language Results:\")\n",
    "for group, metrics in language_results.items():\n",
    "    print(f\"{group}: {metrics}\")\n",
    "\n",
    "children_mapping = {1.0: 'has_child', 0.0: 'not'}\n",
    "\n",
    "children_results = evaluate_model_by_group(\n",
    "    testing_session=testing_session,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    group_column='relatie_kind_heeft_kinderen',\n",
    "    group_mapping=children_mapping\n",
    ")\n",
    "\n",
    "print(\"Children Results:\")\n",
    "for group, metrics in children_results.items():\n",
    "    print(f\"{group}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81617706-0449-4a78-9d9a-279805a1224e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for Predicate 1:\n",
      "  Disparate Impact: 0.9025\n",
      "  Statistical Parity Difference: -0.0774\n",
      "--------------------------------------------------\n",
      "Stats for Predicate 2:\n",
      "  Disparate Impact: 0.8070\n",
      "  Statistical Parity Difference: -0.1533\n",
      "--------------------------------------------------\n",
      "Stats for Predicate 3:\n",
      "  Disparate Impact: 0.8709\n",
      "  Statistical Parity Difference: -0.1023\n",
      "--------------------------------------------------\n",
      "Stats for Predicate 4:\n",
      "  Disparate Impact: 0.5659\n",
      "  Statistical Parity Difference: -0.3476\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def calculate_fairness_stats(privileged_total, privileged_checked, unprivileged_total, unprivileged_checked):\n",
    "    unprivileged_unchecked = unprivileged_total - unprivileged_checked\n",
    "    privileged_unchecked = privileged_total - privileged_checked\n",
    "\n",
    "    favorable_outcome_given_unprivileged = unprivileged_unchecked / unprivileged_total if unprivileged_total > 0 else 0\n",
    "    favorable_outcome_given_privileged = privileged_unchecked / privileged_total if privileged_total > 0 else 0\n",
    "\n",
    "    spd = favorable_outcome_given_unprivileged - favorable_outcome_given_privileged\n",
    "    di = (favorable_outcome_given_unprivileged / favorable_outcome_given_privileged \n",
    "          if favorable_outcome_given_privileged > 0 else float('inf'))\n",
    "\n",
    "    return {\n",
    "        \"Disparate Impact\": di,\n",
    "        \"Statistical Parity Difference\": spd\n",
    "    }\n",
    "\n",
    "# Helper function to evaluate predicates\n",
    "def evaluate_predicate(df, predicate):\n",
    "    return df.loc[predicate(df)], df.loc[~predicate(df)]\n",
    "\n",
    "# Function to calculate and display fairness statistics for predicates\n",
    "def calculate_and_display_fairness(df, predicates, checked_col):\n",
    "    for i, predicate in enumerate(predicates):\n",
    "        # Apply the predicate\n",
    "        subset, subset_complement = evaluate_predicate(df, predicate)\n",
    "        \n",
    "        # Calculate counts\n",
    "        total_count = subset.shape[0]\n",
    "        checked_count = subset[subset[checked_col] == True].shape[0]\n",
    "        total_count_complement = subset_complement.shape[0]\n",
    "        checked_count_complement = subset_complement[subset_complement[checked_col] == True].shape[0]\n",
    "\n",
    "        # Calculate fairness statistics\n",
    "        fairness_stats = calculate_fairness_stats(\n",
    "            total_count_complement, checked_count_complement, \n",
    "            total_count, checked_count\n",
    "        )\n",
    "\n",
    "        # Display results\n",
    "        print(f\"Stats for Predicate {i+1}:\")\n",
    "        for stat, value in fairness_stats.items():\n",
    "            print(f\"  {stat}: {value:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Reusable predicate functions\n",
    "def is_in_age_range(min_age, max_age):\n",
    "    return lambda df: (df['persoon_leeftijd_bij_onderzoek'] >= min_age) & (df['persoon_leeftijd_bij_onderzoek'] < max_age)\n",
    "\n",
    "def is_female():\n",
    "    return lambda df: df['persoon_geslacht_vrouw'] == True\n",
    "\n",
    "def is_male():\n",
    "    return lambda df: df['persoon_geslacht_vrouw'] == False\n",
    "\n",
    "def has_children():\n",
    "    return lambda df: df['relatie_kind_heeft_kinderen'] == True\n",
    "\n",
    "def no_children():\n",
    "    return lambda df: df['relatie_kind_heeft_kinderen'] == False\n",
    "\n",
    "def has_roommate():\n",
    "    return lambda df: df['relatie_overig_kostendeler'] == True\n",
    "    \n",
    "def lacks_language_skills():\n",
    "    return lambda df: df['persoonlijke_eigenschappen_taaleis_voldaan'] == False\n",
    "\n",
    "def has_language_skills():\n",
    "    return lambda df: df['persoonlijke_eigenschappen_taaleis_voldaan'] == True\n",
    "\n",
    "def lives_in_district(district):\n",
    "    return lambda df: df[f'adres_recentste_wijk_{district}'] == True\n",
    "\n",
    "def financial_difficulties():\n",
    "    return lambda df: df['belemmering_financiele_problemen'] == True\n",
    "\n",
    "def combine_and(*predicates):\n",
    "    return lambda df: np.logical_and.reduce([predicate(df) for predicate in predicates])\n",
    "\n",
    "def combine_or(*predicates):\n",
    "    return lambda df: np.logical_or.reduce([predicate(df) for predicate in predicates])\n",
    "\n",
    "\n",
    "\n",
    "session = rt.InferenceSession(\"./received_folder/model_1.onnx\")\n",
    "\n",
    "# Prepare the input for the ONNX model\n",
    "input_name = session.get_inputs()[0].name\n",
    "X_test_np = X_test.to_numpy().astype('float32')\n",
    "\n",
    "# Run predictions using the ONNX model\n",
    "predictions = session.run(None, {input_name: X_test_np})[0]\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "df = X_test.copy()  # Copy X_test to the new dataframe\n",
    "df['checked'] = predictions  # Add predictions as the 'checked' column\n",
    "# Define predicates\n",
    "predicates = [\n",
    "    is_in_age_range(0, 30),\n",
    "    is_in_age_range(66, 120),\n",
    "    combine_and(is_male(), is_in_age_range(20, 35), has_children()),\n",
    "    combine_and(has_roommate(), financial_difficulties(), lacks_language_skills())\n",
    "]\n",
    "\n",
    "\n",
    "# Calculate and display fairness statistics\n",
    "calculate_and_display_fairness(df, predicates, 'checked')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Software-Testing-Project-CokUEsl4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
